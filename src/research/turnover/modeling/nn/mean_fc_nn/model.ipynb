{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitvenvvenv5ea2b9d028884ecdb1defa97f4866164",
   "display_name": "Python 3.6.9 64-bit ('.venv': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Concatenate, Lambda, Bidirectional, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING = 'BERT'\n",
    "\n",
    "MAX_NOMENCLATURE_LEN = {'BERT': 23, 'fastText': 17}[EMBEDDING]\n",
    "MAX_DESCRIPTION_LEN = {'BERT': 45, 'fastText': 30}[EMBEDDING]\n",
    "EMBEDDING_VEC_LEN = {'BERT': 768, 'fastText': 300}[EMBEDDING]\n",
    "\n",
    "MAX_EPOCHS = 300\n",
    "EARLY_STOP_PATIENCE = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Move to commons\n",
    "\n",
    "def load_dfs():\n",
    "    train_df = pd.read_csv('../../../../../resources/dataset/turnover/cleared_train.tsv', sep='\\t')\n",
    "    test_df = pd.read_csv('../../../../../resources/dataset/turnover/cleared_test.tsv', sep='\\t')\n",
    "    original_test_df = pd.read_csv('../../../../../resources/dataset/turnover/original_test.tsv', sep='\\t')\n",
    "\n",
    "    train_df.fillna('', inplace=True)\n",
    "    test_df.fillna('', inplace=True)\n",
    "    original_test_df.fillna('', inplace=True)\n",
    "\n",
    "    with open('../../../../../resources/dataset/turnover/label_encoder.pkl', 'rb') as fin:\n",
    "        le = pickle.load(fin)\n",
    "\n",
    "    train_df.turnover = le.transform(train_df.turnover)\n",
    "    test_df.turnover = le.transform(test_df.turnover)\n",
    "    original_test_df.turnover = le.transform(original_test_df.turnover)\n",
    "\n",
    "    return train_df, test_df, original_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, original_test_df = load_dfs()\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../../../../../resources/cache/{EMBEDDING.lower()}_embedding_map.pkl', 'rb') as fin:\n",
    "    embedding_map = pickle.load(fin)\n",
    "\n",
    "embedding_map['description'][''] = []\n",
    "\n",
    "def to_vectors(df):\n",
    "    y = to_categorical(df.turnover)\n",
    "    x = [\n",
    "        pad_sequences([embedding_map['nomenclature'][i] for i in df.nomenclature], maxlen=MAX_NOMENCLATURE_LEN, dtype='float32'),\n",
    "        pad_sequences([embedding_map['description'][i] for i in df.description], maxlen=MAX_DESCRIPTION_LEN, dtype='float32')\n",
    "    ]\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = to_vectors(test_df)\n",
    "x_test, y_test = to_vectors(test_df)\n",
    "x_original_test, y_original_test = to_vectors(test_df)\n",
    "\n",
    "x_test[0].shape, x_test[1].shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomenclature_input = Input(shape=(MAX_NOMENCLATURE_LEN, EMBEDDING_VEC_LEN))\n",
    "nomenclature_mean_input = Lambda(lambda it: K.mean(it, axis=1))(nomenclature_input)\n",
    "\n",
    "nomenclature_branch = Dense(512, activation=\"relu\")(nomenclature_mean_input)\n",
    "nomenclature_branch = BatchNormalization()(nomenclature_branch)\n",
    "nomenclature_branch = Dropout(0.2)(nomenclature_branch)\n",
    "\n",
    "\n",
    "description_input = Input(shape=(MAX_DESCRIPTION_LEN, EMBEDDING_VEC_LEN))\n",
    "description_mean_input = Lambda(lambda it: K.mean(it, axis=1))(description_input)\n",
    "\n",
    "description_branch = Dense(512, activation=\"relu\")(description_mean_input)\n",
    "description_branch = BatchNormalization()(description_branch)\n",
    "description_branch = Dropout(0.2)(description_branch)\n",
    "\n",
    "\n",
    "common_branch = Concatenate(axis=1)([nomenclature_branch, description_branch])\n",
    "\n",
    "\n",
    "common_branch = Dense(512, activation=\"relu\")(common_branch)\n",
    "common_branch = BatchNormalization()(common_branch)\n",
    "common_branch = Dropout(0.2)(common_branch)\n",
    "\n",
    "common_branch = Dense(len(train_df.turnover.unique()), activation='softmax')(common_branch)\n",
    "\n",
    "\n",
    "model = Model(inputs=[nomenclature_input, description_input], outputs=common_branch)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam())\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(f\"../../../../../resources/model_checkpoint/turnover/nn/mean_fc_nn/\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_report = model.fit(\n",
    "    x_train, y_train\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=MAX_EPOCHS,\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_loss', patience=EARLY_STOP_PATIENCE, restore_best_weights=True),\n",
    "        ModelCheckpoint(f\"../../../../../resources/model_checkpoint/turnover/nn/mean_fc_nn/model.h5\", monitor='val_loss', save_best_only=True, verbose=1)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../../../../resources/model_checkpoint/turnover/nn/mean_fc_nn/history.txt') as fout:\n",
    "    print(*fit_report.history['val_loss'], file=fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot history"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../../../../../resources/model_checkpoint/turnover/nn/mean_fc_nn/model.h5')"
   ]
  }
 ]
}