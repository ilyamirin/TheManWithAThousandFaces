{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "kernelspec": {
      "name": "python36964bitvenvvenv5ea2b9d028884ecdb1defa97f4866164",
      "display_name": "Python 3.6.9 64-bit ('.venv': venv)"
    },
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RESOURCES_PATH = '../../../../resources'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jbk1g8Fpy3lp"
      },
      "outputs": [],
      "source": [
        "# Google Colab Only {\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dLHWsr1VzfQg"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade -r \"/content/drive/My Drive/SHARE/Financial-Analytics-Classifier/requirements.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NZeSDalU0SyJ"
      },
      "outputs": [],
      "source": [
        "RESOURCES_PATH = '/content/drive/My Drive/SHARE/Financial-Analytics-Classifier/resources'\n",
        "# } Google Colab Only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "qdK6C7gBy3lt"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from time import time, strftime, gmtime\n",
        "import multiprocessing\n",
        "import pickle\n",
        "import json\n",
        "from collections import namedtuple\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import softmax\n",
        "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "DAHrE1Nny3lx"
      },
      "outputs": [],
      "source": [
        "ADDITIONAL_REPORT_METRICS = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "C6sQSTlMy3l1"
      },
      "outputs": [],
      "source": [
        "MAX_SENTENCE_LEN = 50\n",
        "MAX_EPOCHS = 100\n",
        "EARLY_STOP_PATIENCE = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Vaq4AzWWy3l4"
      },
      "outputs": [],
      "source": [
        "Path(f'{RESOURCES_PATH}/model_checkpoint/turnover/bert/').mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "u7EH1_d-y3l9"
      },
      "outputs": [],
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YMZNx_EDy3l-"
      },
      "outputs": [],
      "source": [
        "def load_dfs():\n",
        "    train_df = pd.read_csv(f'{RESOURCES_PATH}/dataset/turnover/cleared_train.tsv', sep='\\t')\n",
        "    test_df = pd.read_csv(f'{RESOURCES_PATH}/dataset/turnover/cleared_test.tsv', sep='\\t')\n",
        "    original_test_df = pd.read_csv(f'{RESOURCES_PATH}/dataset/turnover/original_test.tsv', sep='\\t')\n",
        "\n",
        "    train_df.fillna('', inplace=True)\n",
        "    test_df.fillna('', inplace=True)\n",
        "    original_test_df.fillna('', inplace=True)\n",
        "\n",
        "    with open(f'{RESOURCES_PATH}/dataset/turnover/label_encoder.pkl', 'rb') as fin:\n",
        "        le = pickle.load(fin)\n",
        "\n",
        "    train_df.turnover = le.transform(train_df.turnover)\n",
        "    test_df.turnover = le.transform(test_df.turnover)\n",
        "    original_test_df.turnover = le.transform(original_test_df.turnover)\n",
        "\n",
        "    return train_df, test_df, original_test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "l4NuuoJ6y3mB"
      },
      "outputs": [],
      "source": [
        "train_df, test_df, original_test_df = load_dfs()\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LhPS5ORky3mF"
      },
      "outputs": [],
      "source": [
        "NetInput = namedtuple('NetInput', 'word_tokens attention_mask')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_mdDgWYTy3mJ"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(f'{RESOURCES_PATH}/pretrained/rubert')\n",
        "\n",
        "def to_vectors(df):\n",
        "    word_tokens_list = []\n",
        "    attention_masks = []\n",
        "    for i in range(len(df)):\n",
        "        tokenized = tokenizer.encode_plus(\n",
        "            df.nomenclature[i], \n",
        "            text_pair=df.description[i], \n",
        "            max_length=MAX_SENTENCE_LEN, \n",
        "            pad_to_max_length=True, \n",
        "            return_attention_mask=True, \n",
        "            return_token_type_ids=False\n",
        "        )\n",
        "        word_tokens_list.append(tokenized['input_ids'])\n",
        "        attention_masks.append(tokenized['attention_mask'])\n",
        "    \n",
        "    return NetInput(torch.tensor(word_tokens_list).cuda(), torch.tensor(attention_masks).cuda()), torch.tensor(df.turnover).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3buxD3CXy3mM"
      },
      "outputs": [],
      "source": [
        "x_train, y_train = to_vectors(train_df)\n",
        "x_test, y_test = to_vectors(test_df)\n",
        "x_original_test, y_original_test = to_vectors(original_test_df)\n",
        "\n",
        "x_train.word_tokens.shape, x_train.attention_mask.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Oc4_7e70y3mQ"
      },
      "outputs": [],
      "source": [
        "class DatasetImpl(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return NetInput(self.x.word_tokens[index], self.x.attention_mask[index]), self.y[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "PiDWvXGWy3mU"
      },
      "outputs": [],
      "source": [
        "class ModelImpl(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelImpl, self).__init__()\n",
        "        # TODO not load pretrained on trained model\n",
        "        self.bert_layer = BertModel.from_pretrained(f'{RESOURCES_PATH}/pretrained/rubert')\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.cls_layer = nn.Linear(768, int(y_train.max()+1))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        embeddings, pooled_output = self.bert_layer(x.word_tokens, attention_mask = x.attention_mask)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.cls_layer(pooled_output)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "prbPGCrqy3mP"
      },
      "outputs": [],
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_g9ou_EWy3mX"
      },
      "outputs": [],
      "source": [
        "def log_metrics(model, epoch, history, train_losses, started_at):\n",
        "    with torch.no_grad():\n",
        "        y_pred_logits = model(x_test)\n",
        "        \n",
        "    y_pred_proba = softmax(y_pred_logits.cpu().numpy())\n",
        "\n",
        "    val_acc = accuracy_score(y_test.cpu(), y_pred_proba.argmax(axis=1))\n",
        "    val_loss = log_loss(y_test.cpu(), y_pred_proba)\n",
        "    train_loss = np.array(train_losses).mean()\n",
        "\n",
        "    history.append({\n",
        "        'Validation Accuracy': val_acc,\n",
        "        'Validation Loss': val_loss,\n",
        "        'Train Loss': train_loss\n",
        "    })\n",
        "\n",
        "    formated_training_time = strftime(\"%Hh %Mm %Ss\", gmtime(time() - started_at))\n",
        "\n",
        "    print(f'Epoch #{epoch}: Val. Loss -- {val_loss}, Val. accuracy -- {val_acc}, Train Loss -- {train_loss}, Spent time -- {formated_training_time}')\n",
        "\n",
        "    return val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "CqiHRX6Ey3ma"
      },
      "outputs": [],
      "source": [
        "def fit(model, dataloader, optimizer, criterion):\n",
        "    started_at = time()\n",
        "    history = []\n",
        "\n",
        "    best_epoch = 0\n",
        "    best_loss = 10e100\n",
        "\n",
        "    for epoch in range(1, MAX_EPOCHS+1):\n",
        "        train_losses = []\n",
        "\n",
        "        for x, y in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            y_pred = model(x)\n",
        "\n",
        "            loss = criterion(y_pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_losses.append(float(loss))\n",
        "        \n",
        "        val_loss = log_metrics(model, epoch, history, train_losses, started_at)\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_epoch = epoch\n",
        "            torch.save(model.state_dict(), f'{RESOURCES_PATH}/model_checkpoint/turnover/bert/model.pt')\n",
        "        elif epoch - best_epoch > EARLY_STOP_PATIENCE:\n",
        "            print(f'    Early stop training. Best validation loss - {best_loss} of epoch #{best_epoch}')\n",
        "            break\n",
        "        else:\n",
        "            print(f\"    Validation loss hasn't improved. Current best value - {best_loss} of epoch #{best_epoch}\")\n",
        "    \n",
        "    training_time = time() - started_at\n",
        "\n",
        "    return history, training_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "F-2fN1Lhy3me"
      },
      "outputs": [],
      "source": [
        "model = ModelImpl().cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "DEXOm1wRy3mh"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(DatasetImpl(x_train, y_train), batch_size=128, shuffle=True)\n",
        "\n",
        "history, training_time = fit(model, train_dataloader, optim.Adam(model.parameters(), lr=2e-4), nn.CrossEntropyLoss())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MBNb8Kn2y3mk"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(history).to_csv(f'{RESOURCES_PATH}/model_checkpoint/turnover/bert/history.tsv', index=False, sep='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "qLxZP8yOy3mn"
      },
      "outputs": [],
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3LmNqdepy3mo"
      },
      "outputs": [],
      "source": [
        "history = pd.read_csv(f'{RESOURCES_PATH}/model_checkpoint/turnover/bert/history.tsv', sep='\\t')\n",
        "\n",
        "history[['Validation Loss', 'Train Loss']].plot()\n",
        "plt.xlabel('epoch');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2AWeA7Xsy3mq"
      },
      "outputs": [],
      "source": [
        "def get_report(y_true, y_pred_logits):\n",
        "    y_pred_proba = softmax(y_pred_logits.cpu().numpy())\n",
        "    y_pred = y_pred_proba.argmax(axis=1)\n",
        "\n",
        "    report = {}\n",
        "\n",
        "    report['accuracy'] = round(accuracy_score(y_true.cpu(), y_pred), 4)\n",
        "    report['log_loss'] = round(log_loss(y_true.cpu(), y_pred_proba), 4)\n",
        "\n",
        "    if 'confusion_matrix' in ADDITIONAL_REPORT_METRICS:\n",
        "        report['confusion_matrix'] = confusion_matrix(y_true.cpu(), y_pred)\n",
        "\n",
        "    return report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4OJJSrEly3mu"
      },
      "outputs": [],
      "source": [
        "def expand_to_original_dataset_size(y_pred_logits):\n",
        "    original_y_size_diff = int(y_original_test.max()+1) - y_pred_logits.shape[1]\n",
        "    padded = np.pad(y_pred_logits.cpu(), ((0, 0), (0, original_y_size_diff)), 'constant', constant_values=(0, 0))\n",
        "    return torch.tensor(padded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cXgla3TLy3mx"
      },
      "outputs": [],
      "source": [
        "model = ModelImpl().cuda()\n",
        "model.load_state_dict(torch.load(f'{RESOURCES_PATH}/model_checkpoint/turnover/bert/model.pt'))\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "aAk-bvpay3m0"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    y_pred_logits = model(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jPJwzBrxQIS1"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    y_pred_parts = []\n",
        "    for x, y in DataLoader(DatasetImpl(x_original_test, y_original_test), batch_size=1024):\n",
        "        y_pred_parts.append(model(x))\n",
        "\n",
        "    y_original_pred_logits = torch.cat(y_pred_parts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wkL7Aad7y3m3"
      },
      "outputs": [],
      "source": [
        "cleared_report = get_report(y_test, y_pred_logits)\n",
        "original_report = get_report(y_original_test, expand_to_original_dataset_size(y_original_pred_logits))\n",
        "\n",
        "report = {\n",
        "    'Name': f'Fine-Tunned BERT',\n",
        "    '[Cleared Test] Accuracy': cleared_report['accuracy'],\n",
        "    '[Cleared Test] Log Loss': cleared_report['log_loss'],\n",
        "    '[Original Test] Accuracy': original_report['accuracy'],\n",
        "    '[Original Test] Log Loss': original_report['log_loss'],\n",
        "    'Training time': strftime(\"%Hh %Mm %Ss\", gmtime(training_time)),\n",
        "    'Training time (sec)': int(training_time),\n",
        "    'Model epoch': history[\"Validation Loss\"].idxmin()+1,\n",
        "    'Epochs': len(history)\n",
        "}\n",
        "\n",
        "print(json.dumps(report, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ow0QTPXXixTZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}