{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitvenvvenv5ea2b9d028884ecdb1defa97f4866164",
   "display_name": "Python 3.6.9 64-bit ('.venv': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fasttext\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleared_train_df = pd.read_csv('../../resources/dataset/turnover/cleared_train.tsv', sep='\\t')\n",
    "cleared_test_df = pd.read_csv('../../resources/dataset/turnover/cleared_test.tsv', sep='\\t')\n",
    "original_test_df = pd.read_csv('../../resources/dataset/turnover/original_test.tsv', sep='\\t')\n",
    "\n",
    "cleared_train_df.fillna('', inplace=True)\n",
    "cleared_test_df.fillna('', inplace=True)\n",
    "original_test_df.fillna('', inplace=True)\n",
    "\n",
    "cleared_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    lower_cased = text.lower()\n",
    "    without_special_chars = re.sub(r\"[^a-zА-я0-9 ]\", '', lower_cased)\n",
    "    without_excess_spaces = re.sub(r\" {2,}\", ' ', without_special_chars)\n",
    "    stripped = without_excess_spaces.strip()\n",
    "    return stripped\n",
    "\n",
    "clear_text('Hello World, A4 \"Привет мир\": 8394! » | ¶ 42')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = set()\n",
    "\n",
    "phrases = phrases.union(cleared_train_df.nomenclature.unique())\n",
    "phrases = phrases.union(cleared_train_df.description.unique())\n",
    "\n",
    "phrases = phrases.union(cleared_test_df.nomenclature.unique())\n",
    "phrases = phrases.union(cleared_test_df.description.unique())\n",
    "\n",
    "phrases = phrases.union(original_test_df.nomenclature.unique())\n",
    "phrases = phrases.union(original_test_df.description.unique())\n",
    "\n",
    "phrases = list(map(clear_text, phrases))\n",
    "\n",
    "phrases.remove('')\n",
    "\n",
    "len(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"../../resources/cache\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embed phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_map(to_vector_fn):\n",
    "    result = {'': np.array([np.zeros(300)])}\n",
    "\n",
    "    for i in range(len(phrases)):\n",
    "        if i % 1000 == 0: print(f\"Embedded {round(i / len(phrases) * 100)}%\")\n",
    "        result[phrases[i]] = to_vector_fn(phrases[i])\n",
    "    \n",
    "    print(\"Completed\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = fasttext.load_model(\"../../resources/embedding/dp-fasttext.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_fasttext_vector(phrase):\n",
    "    return np.array(list(map(ft_model.get_word_vector, phrase.split())))\n",
    "\n",
    "to_fasttext_vector('Привет мир').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_embedding_map = get_embedding_map(to_fasttext_vector)\n",
    "\n",
    "with open('../../resources/cache/fasttext_embedding_map.pkl', 'wb') as fout:\n",
    "    pickle.dump(ft_embedding_map, fout, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('../../resources/embedding/rubert')\n",
    "bert_model = BertModel.from_pretrained('../../resources/embedding/rubert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Vectorize\n",
    "\n",
    "def to_bert_vector(phrase):\n",
    "    input_ids = torch.tensor([bert_tokenizer.encode(phrase, add_special_tokens=False)])\n",
    "    layers, _ = bert_model(input_ids)\n",
    "    return layers.detach().numpy()[0]\n",
    "\n",
    "to_bert_vector('Привет мир').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embedding_map = get_embedding_map(to_bert_vector)\n",
    "\n",
    "with open('../../resources/cache/bert_embedding_map.pkl', 'wb') as fout:\n",
    "    pickle.dump(bert_embedding_map, fout, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chose optimal max embedding length"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../resources/cache/fasttext_embedding_map.pkl', 'rb') as fin:\n",
    "    ft_embedding_map = pickle.load(fin)\n",
    "\n",
    "ft_embedding_len_df = pd.DataFrame({'phrase': phrases, 'len': [len(ft_embedding_map[phrase]) for phrase in phrases]})\n",
    "\n",
    "print(f'''\n",
    "fastText length quantile:\n",
    "\n",
    "{ft_embedding_len_df.len.quantile([.5, .9, .95, .99, .999])}\n",
    "\n",
    "=> fastText optimal max length is 30\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../resources/cache/bert_embedding_map.pkl', 'rb') as fin:\n",
    "    bert_embedding_map = pickle.load(fin)\n",
    "\n",
    "bert_embedding_len_df = pd.DataFrame({'phrase': phrases, 'len': [len(bert_embedding_map[phrase]) for phrase in phrases]})\n",
    "\n",
    "print(f'''\n",
    "BERT length quantile:\n",
    "\n",
    "{bert_embedding_len_df.len.quantile([.5, .9, .95, .99, .999])}\n",
    "\n",
    "=> BERT optimal max length is 40\n",
    "''')"
   ]
  }
 ]
}