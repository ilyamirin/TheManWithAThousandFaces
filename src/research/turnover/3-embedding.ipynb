{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitvenvvenv5ea2b9d028884ecdb1defa97f4866164",
   "display_name": "Python 3.6.9 64-bit ('.venv': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fasttext\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nomenclature</th>\n      <th>description</th>\n      <th>turnover</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Поставка медицинского оборудования</td>\n      <td>Тренажер назогастрального кормления</td>\n      <td>310.09 Приобретение медицинского оборудования</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Поставка  лабораторного оборудования и материалов</td>\n      <td>оборудование для лаб. Аддитивных технологий</td>\n      <td>310.03 Приобретение научно-лабораторного обору...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Поставка расходных материалов (реагенты сложны...</td>\n      <td>Камфора, кг</td>\n      <td>346.10 Хим. реактивы, хим.посуда</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Поставка лабораторных расходных материалов</td>\n      <td>Пеленка впитывающая</td>\n      <td>346.10 Хим. реактивы, хим.посуда</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ведро оцинкованное</td>\n      <td>Ведро с ручкой, оцинкованное, без крышки. Ведр...</td>\n      <td>346.22 Прочие материальные запасы</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                        nomenclature  \\\n0                 Поставка медицинского оборудования   \n1  Поставка  лабораторного оборудования и материалов   \n2  Поставка расходных материалов (реагенты сложны...   \n3         Поставка лабораторных расходных материалов   \n4                                 Ведро оцинкованное   \n\n                                         description  \\\n0                Тренажер назогастрального кормления   \n1        оборудование для лаб. Аддитивных технологий   \n2                                        Камфора, кг   \n3                                Пеленка впитывающая   \n4  Ведро с ручкой, оцинкованное, без крышки. Ведр...   \n\n                                            turnover  count  \n0      310.09 Приобретение медицинского оборудования      6  \n1  310.03 Приобретение научно-лабораторного обору...      3  \n2                   346.10 Хим. реактивы, хим.посуда     10  \n3                   346.10 Хим. реактивы, хим.посуда      3  \n4                  346.22 Прочие материальные запасы      6  "
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleared_train_df = pd.read_csv('../../resources/dataset/turnover/cleared_train.tsv', sep='\\t')\n",
    "cleared_test_df = pd.read_csv('../../resources/dataset/turnover/cleared_test.tsv', sep='\\t')\n",
    "original_test_df = pd.read_csv('../../resources/dataset/turnover/original_test.tsv', sep='\\t')\n",
    "\n",
    "cleared_train_df.fillna('', inplace=True)\n",
    "cleared_test_df.fillna('', inplace=True)\n",
    "original_test_df.fillna('', inplace=True)\n",
    "\n",
    "cleared_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'hello world a4 привет мир 8394 42'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clear_text(text):\n",
    "    lower_cased = text.lower()\n",
    "    without_special_chars = re.sub(r\"[^a-zА-я0-9 ]\", '', lower_cased)\n",
    "    without_excess_spaces = re.sub(r\" {2,}\", ' ', without_special_chars)\n",
    "    stripped = without_excess_spaces.strip()\n",
    "    return stripped\n",
    "\n",
    "clear_text('Hello World, A4 \"Привет мир\": 8394! » | ¶ 42')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "834"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomenclatures = set()\n",
    "\n",
    "nomenclatures = nomenclatures.union(cleared_train_df.nomenclature.unique())\n",
    "nomenclatures = nomenclatures.union(cleared_test_df.nomenclature.unique())\n",
    "nomenclatures = nomenclatures.union(original_test_df.nomenclature.unique())\n",
    "\n",
    "nomenclatures = list(nomenclatures)\n",
    "\n",
    "len(nomenclatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "7596"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions = set()\n",
    "\n",
    "descriptions = descriptions.union(cleared_train_df.description.unique())\n",
    "descriptions = descriptions.union(cleared_test_df.description.unique())\n",
    "descriptions = descriptions.union(original_test_df.description.unique())\n",
    "\n",
    "descriptions.remove('')\n",
    "\n",
    "descriptions = list(descriptions)\n",
    "\n",
    "len(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"../../resources/cache\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embed phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_map(to_vector_fn):\n",
    "    result = {\n",
    "        'nomenclature': {},\n",
    "        'description': {'': np.array([])}\n",
    "    }\n",
    "\n",
    "    for i in range(len(nomenclatures)):\n",
    "        result['nomenclature'][nomenclatures[i]] = to_vector_fn(clear_text(nomenclatures[i]))\n",
    "\n",
    "    print(\"Nomenclature embedding is complete\")\n",
    "\n",
    "    for i in range(len(descriptions)):\n",
    "        if i % 1000 == 0: print(f\"Description embedded {round(i / len(descriptions) * 100)}%\")\n",
    "        result['description'][descriptions[i]] = to_vector_fn(clear_text(descriptions[i]))\n",
    "    \n",
    "    print(\"Description embedding is complete\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = fasttext.load_model(\"../../resources/embedding/dp-fasttext.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_fasttext_vector(phrase):\n",
    "    return np.array(list(map(ft_model.get_word_vector, phrase.split())))\n",
    "\n",
    "to_fasttext_vector('Привет мир').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_embedding_map = get_embedding_map(to_fasttext_vector)\n",
    "\n",
    "with open('../../resources/cache/fasttext_embedding_map.pkl', 'wb') as fout:\n",
    "    pickle.dump(ft_embedding_map, fout, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('../../resources/embedding/rubert')\n",
    "bert_model = BertModel.from_pretrained('../../resources/embedding/rubert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(4, 768)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Vectorize\n",
    "\n",
    "def to_bert_vector(phrase):\n",
    "    input_ids = torch.tensor([bert_tokenizer.encode(phrase)])\n",
    "    layers, _ = bert_model(input_ids)\n",
    "    return layers.detach().numpy()[0]\n",
    "\n",
    "to_bert_vector('Привет мир').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Nomenclature embedding is complete\nDescription embedded 0%\nDescription embedded 13%\nDescription embedded 26%\nDescription embedded 39%\nDescription embedded 53%\nDescription embedded 66%\nDescription embedded 79%\nDescription embedded 92%\nDescription embedding is complete\n"
    }
   ],
   "source": [
    "bert_embedding_map = get_embedding_map(to_bert_vector)\n",
    "\n",
    "with open('../../resources/cache/bert_embedding_map.pkl', 'wb') as fout:\n",
    "    pickle.dump(bert_embedding_map, fout, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chose optimal max embedding length"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../resources/cache/fasttext_embedding_map.pkl', 'rb') as fin:\n",
    "    ft_embedding_map = pickle.load(fin)\n",
    "\n",
    "print(f'''\n",
    "fastText length quantile:\n",
    "\n",
    "Nomenclature:\n",
    "{pd.Series([len(ft_embedding_map['nomenclature'][k]) for k in ft_embedding_map['nomenclature']]).quantile([.5, .9, .95, .99, .999])}\n",
    "\n",
    "Description:\n",
    "{pd.Series([len(ft_embedding_map['description'][k]) for k in ft_embedding_map['description']]).quantile([.5, .9, .95, .99, .999])}\n",
    "\n",
    "=> fastText optimal max length:\n",
    "    nomenclature: 17\n",
    "    description: 30\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../resources/cache/bert_embedding_map.pkl', 'rb') as fin:\n",
    "    bert_embedding_map = pickle.load(fin)\n",
    "\n",
    "print(f'''\n",
    "BERT length quantile:\n",
    "\n",
    "Nomenclature:\n",
    "{pd.Series([len(bert_embedding_map['nomenclature'][k]) for k in bert_embedding_map['nomenclature']]).quantile([.5, .9, .95, .99, .999])}\n",
    "\n",
    "Description:\n",
    "{pd.Series([len(bert_embedding_map['description'][k]) for k in bert_embedding_map['description']]).quantile([.5, .9, .95, .99, .999])}\n",
    "\n",
    "=> BERT optimal max length:\n",
    "    nomenclature: 23\n",
    "    description: 45\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}