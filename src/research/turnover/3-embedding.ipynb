{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitvenvvenv5ea2b9d028884ecdb1defa97f4866164",
   "display_name": "Python 3.6.9 64-bit ('.venv': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOURCES_PATH = '../../resources'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fasttext\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleared_train_df = pd.read_csv(f'{RESOURCES_PATH}/dataset/turnover/cleared_train.tsv', sep='\\t')\n",
    "cleared_test_df = pd.read_csv(f'{RESOURCES_PATH}/dataset/turnover/cleared_test.tsv', sep='\\t')\n",
    "original_test_df = pd.read_csv(f'{RESOURCES_PATH}/dataset/turnover/original_test.tsv', sep='\\t')\n",
    "\n",
    "cleared_train_df.fillna('', inplace=True)\n",
    "cleared_test_df.fillna('', inplace=True)\n",
    "original_test_df.fillna('', inplace=True)\n",
    "\n",
    "cleared_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    lower_cased = text.lower()\n",
    "    without_special_chars = re.sub(r\"[^a-zА-я0-9 ]\", '', lower_cased)\n",
    "    without_excess_spaces = re.sub(r\" {2,}\", ' ', without_special_chars)\n",
    "    stripped = without_excess_spaces.strip()\n",
    "    return stripped\n",
    "\n",
    "clear_text('Hello World, A4 \"Привет мир\": 8394! » | ¶ 42')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomenclatures = set()\n",
    "\n",
    "nomenclatures = nomenclatures.union(cleared_train_df.nomenclature.unique())\n",
    "nomenclatures = nomenclatures.union(cleared_test_df.nomenclature.unique())\n",
    "nomenclatures = nomenclatures.union(original_test_df.nomenclature.unique())\n",
    "\n",
    "nomenclatures = list(nomenclatures)\n",
    "\n",
    "len(nomenclatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = set()\n",
    "\n",
    "descriptions = descriptions.union(cleared_train_df.description.unique())\n",
    "descriptions = descriptions.union(cleared_test_df.description.unique())\n",
    "descriptions = descriptions.union(original_test_df.description.unique())\n",
    "\n",
    "descriptions.remove('')\n",
    "\n",
    "descriptions = list(descriptions)\n",
    "\n",
    "len(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(f'{RESOURCES_PATH}/cache').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embed phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_map(to_vector_fn):\n",
    "    result = {\n",
    "        'nomenclature': {},\n",
    "        'description': {'': np.array([])}\n",
    "    }\n",
    "\n",
    "    for i in range(len(nomenclatures)):\n",
    "        result['nomenclature'][nomenclatures[i]] = to_vector_fn(clear_text(nomenclatures[i]))\n",
    "\n",
    "    print(\"Nomenclature embedding is complete\")\n",
    "\n",
    "    for i in range(len(descriptions)):\n",
    "        if i % 1000 == 0: print(f\"Description embedded {round(i / len(descriptions) * 100)}%\")\n",
    "        result['description'][descriptions[i]] = to_vector_fn(clear_text(descriptions[i]))\n",
    "    \n",
    "    print(\"Description embedding is complete\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = fasttext.load_model(f'{RESOURCES_PATH}/pretrained/dp-fasttext.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_fasttext_vector(phrase):\n",
    "    return np.array(list(map(ft_model.get_word_vector, phrase.split())))\n",
    "\n",
    "to_fasttext_vector('Привет мир').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_embedding_map = get_embedding_map(to_fasttext_vector)\n",
    "\n",
    "with open(f'{RESOURCES_PATH}/cache/fasttext_embedding_map.pkl', 'wb') as fout:\n",
    "    pickle.dump(ft_embedding_map, fout, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained(f'{RESOURCES_PATH}/pretrained/rubert')\n",
    "bert_model = BertModel.from_pretrained(f'{RESOURCES_PATH}/pretrained/rubert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bert_vector(phrase):\n",
    "    input_ids = torch.tensor([bert_tokenizer.encode(phrase)])\n",
    "    layers, _ = bert_model(input_ids)\n",
    "    return layers.detach().numpy()[0]\n",
    "\n",
    "to_bert_vector('Привет мир').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embedding_map = get_embedding_map(to_bert_vector)\n",
    "\n",
    "with open(f'{RESOURCES_PATH}/cache/bert_embedding_map.pkl', 'wb') as fout:\n",
    "    pickle.dump(bert_embedding_map, fout, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chose optimal max embedding length"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{RESOURCES_PATH}/cache/fasttext_embedding_map.pkl', 'rb') as fin:\n",
    "    ft_embedding_map = pickle.load(fin)\n",
    "\n",
    "print(f'''\n",
    "fastText length quantile:\n",
    "\n",
    "Nomenclature:\n",
    "{pd.Series([len(ft_embedding_map['nomenclature'][k]) for k in ft_embedding_map['nomenclature']]).quantile([.5, .9, .95, .99, .999])}\n",
    "\n",
    "Description:\n",
    "{pd.Series([len(ft_embedding_map['description'][k]) for k in ft_embedding_map['description']]).quantile([.5, .9, .95, .99, .999])}\n",
    "\n",
    "=> fastText optimal max length:\n",
    "    nomenclature: 17\n",
    "    description: 30\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{RESOURCES_PATH}/cache/bert_embedding_map.pkl', 'rb') as fin:\n",
    "    bert_embedding_map = pickle.load(fin)\n",
    "\n",
    "print(f'''\n",
    "BERT length quantile:\n",
    "\n",
    "Nomenclature:\n",
    "{pd.Series([len(bert_embedding_map['nomenclature'][k]) for k in bert_embedding_map['nomenclature']]).quantile([.5, .9, .95, .99, .999])}\n",
    "\n",
    "Description:\n",
    "{pd.Series([len(bert_embedding_map['description'][k]) for k in bert_embedding_map['description']]).quantile([.5, .9, .95, .99, .999])}\n",
    "\n",
    "=> BERT optimal max length:\n",
    "    nomenclature: 23\n",
    "    description: 45\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}