{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitvenvvenv5ea2b9d028884ecdb1defa97f4866164",
   "display_name": "Python 3.6.9 64-bit ('.venv': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOURCES_PATH = '../../../resources'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = 'categorical_ffnn'\n",
    "\n",
    "MAX_EPOCHS = 300\n",
    "EARLY_STOP_PATIENCE = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from time import time, strftime, gmtime\n",
    "import pickle\n",
    "import multiprocessing\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.special import softmax\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import torch\n",
    "from torch import tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(f'{RESOURCES_PATH}/model_checkpoint/budget/{NAME}/').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & prepare data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{RESOURCES_PATH}/dataset/budget/cleared.tsv', sep='\\t').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_le = LabelEncoder()\n",
    "budget_le.classes_ = np.array(Path(f'{RESOURCES_PATH}/dataset/budget/targets.txt').read_text().split('\\n'))\n",
    "\n",
    "object_le = LabelEncoder()\n",
    "object_le.fit(df.object)\n",
    "\n",
    "project_le = LabelEncoder()\n",
    "project_le.fit(df.project)\n",
    "\n",
    "financing_le = LabelEncoder()\n",
    "financing_le.fit(df.financing);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NetInput = namedtuple('NetInput', 'object project financing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_vectors(df):\n",
    "    y = budget_le.transform(df.budget)\n",
    "    x_object = to_categorical(object_le.transform(df.object))\n",
    "    x_project = to_categorical(project_le.transform(df.project))\n",
    "    x_financing = to_categorical(financing_le.transform(df.financing))\n",
    "\n",
    "    return NetInput(tensor(x_object), tensor(x_project), tensor(x_financing)), tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = to_vectors(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetImpl(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return NetInput(self.x.object[index], self.x.project[index], self.x.financing[index]), self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelImpl(nn.Module):\n",
    "    def __init__(self, optimizer_fn=None, loss=None):\n",
    "        super(ModelImpl, self).__init__()\n",
    "\n",
    "        self.object_linear = nn.Linear(x.object.shape[1], 512)\n",
    "        self.object_batch_norm = nn.BatchNorm1d(512)\n",
    "        self.object_dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        self.project_linear = nn.Linear(x.project.shape[1], 512)\n",
    "        self.project_batch_norm = nn.BatchNorm1d(512)\n",
    "        self.project_dropout = nn.Dropout(0.2)\n",
    "\n",
    "        self.financing_linear = nn.Linear(x.financing.shape[1], 512)\n",
    "        self.financing_batch_norm = nn.BatchNorm1d(512)\n",
    "        self.financing_dropout = nn.Dropout(0.2)\n",
    "\n",
    "        self.common_linear = nn.Linear(512 * 3, 512)\n",
    "        self.common_batch_norm = nn.BatchNorm1d(512)\n",
    "        self.common_dropout = nn.Dropout(0.2)\n",
    "\n",
    "        self.cls_linear = nn.Linear(512, int(y.max()+1))\n",
    "\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer_fn(self) if optimizer_fn != None else None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        obj_branch = self.object_linear(x.object)\n",
    "        obj_branch = self.object_batch_norm(obj_branch)\n",
    "        obj_branch = F.relu(obj_branch)\n",
    "        obj_branch = self.object_dropout(obj_branch)\n",
    "\n",
    "        prj_branch = self.project_linear(x.project)\n",
    "        prj_branch = self.project_batch_norm(prj_branch)\n",
    "        prj_branch = F.relu(prj_branch)\n",
    "        prj_branch = self.project_dropout(prj_branch)\n",
    "\n",
    "        fin_branch = self.financing_linear(x.financing)\n",
    "        fin_branch = self.financing_batch_norm(fin_branch)\n",
    "        fin_branch = F.relu(fin_branch)\n",
    "        fin_branch = self.financing_dropout(fin_branch)\n",
    "\n",
    "        concatenated_branches = torch.cat((obj_branch, prj_branch, fin_branch), dim=1)\n",
    "\n",
    "        common_branch = self.common_linear(concatenated_branches)\n",
    "        common_branch = self.common_batch_norm(common_branch)\n",
    "        common_branch = F.relu(common_branch)\n",
    "        common_branch = self.common_dropout(common_branch)\n",
    "\n",
    "        logits = self.cls_linear(common_branch)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_i, val_i = next(StratifiedKFold(10, shuffle=True, random_state=42).split(x.object, y))\n",
    "\n",
    "x_train, y_train = DatasetImpl(x, y)[train_i]\n",
    "x_val, y_val = DatasetImpl(x, y)[val_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(model, epoch, history, train_losses, started_at):\n",
    "    with torch.no_grad():\n",
    "        y_val_logits = model(x_val)\n",
    "        y_val_proba = softmax(y_val_logits.numpy())\n",
    "\n",
    "    val_acc = accuracy_score(y_val, y_val_proba.argmax(axis=1))\n",
    "    val_loss = log_loss(y_val, y_val_proba, labels=y.unique())\n",
    "    train_loss = np.array(train_losses).mean()\n",
    "\n",
    "    history.append({\n",
    "        'Validation Accuracy': val_acc,\n",
    "        'Validation Loss': val_loss,\n",
    "        'Train Loss': train_loss\n",
    "    })\n",
    "\n",
    "    print(f'Epoch #{epoch}: Val. Loss -- {val_loss}, Train Loss -- {train_loss}, Spent time -- {strftime(\"%Hh %Mm %Ss\", gmtime(time() - started_at))}')\n",
    "\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, dataloader):\n",
    "    started_at = time()\n",
    "    history = []\n",
    "\n",
    "    best_epoch = 0\n",
    "    best_loss = 10e100\n",
    "\n",
    "    for epoch in range(1, MAX_EPOCHS):\n",
    "        train_losses = []\n",
    "\n",
    "        for x, y in dataloader:\n",
    "            y_pred = model(x)\n",
    "\n",
    "            loss = model.loss(y_pred, y)\n",
    "            loss.backward()\n",
    "\n",
    "            model.optimizer.step()\n",
    "            model.optimizer.zero_grad()\n",
    "\n",
    "            train_losses.append(float(loss))\n",
    "        \n",
    "        val_loss = log_metrics(model, epoch, history, train_losses, started_at)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "            torch.save(model, f'{RESOURCES_PATH}/model_checkpoint/budget/{NAME}/model.pt')\n",
    "        elif epoch - best_epoch > EARLY_STOP_PATIENCE:\n",
    "            print(f'    Early stop training. Best validation loss - {best_loss} of epoch #{best_epoch}')\n",
    "            break\n",
    "        else:\n",
    "            print(f\"    Validation loss hasn't improved. Current best value - {best_loss} of epoch #{best_epoch}\")\n",
    "    \n",
    "    training_time = time() - started_at\n",
    "\n",
    "    return history, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelImpl(\n",
    "    lambda model: optim.Adam(model.parameters(), lr=1e-4),\n",
    "    nn.CrossEntropyLoss()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "history, training_time = fit(model, DataLoader(DatasetImpl(x_train, y_train), batch_size=64, shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history).to_csv(f'{RESOURCES_PATH}/model_checkpoint/budget/{NAME}/history.tsv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.read_csv(f'{RESOURCES_PATH}/model_checkpoint/budget/{NAME}/history.tsv', sep='\\t')\n",
    "history[['Validation Loss', 'Train Loss']].plot()\n",
    "plt.xlabel('epoch');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df = pd.read_csv(f'{RESOURCES_PATH}/dataset/budget/original.tsv', sep='\\t').fillna('')\n",
    "x_orig, y_orig = to_vectors(orig_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_orig_shape(y_pred_proba):\n",
    "    shape_diff = len(budget_le.classes_) - y_pred_proba.shape[1] - 1\n",
    "    return tensor(np.pad(y_pred_proba, ((0, 0), (0, shape_diff)), 'constant', constant_values=(0, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(f'{RESOURCES_PATH}/model_checkpoint/budget/{NAME}/model.pt')\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_val_logits = model(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_orig_logits = model(x_orig)\n",
    "    y_orig_logits = to_orig_shape(y_orig_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_report(y_true, y_pred_logits):\n",
    "    y_pred_proba = softmax(y_pred_logits.numpy())\n",
    "    return round(accuracy_score(y_true, y_pred_proba.argmax(axis=1)), 4)\n",
    "\n",
    "def logloss_report(y_true, y_pred_logits):\n",
    "    y_pred_proba = softmax(y_pred_logits.numpy())\n",
    "    return round(log_loss(y_true, y_pred_proba, labels=range(y_pred_logits.shape[1])), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = {\n",
    "    'Name': f'Categorical Feed-Forward NN',\n",
    "    '[Cleared] Accuracy': accuracy_report(y_val, y_val_logits),\n",
    "    '[Cleared] Log Loss': logloss_report(y_val, y_val_logits),\n",
    "    '[Original] Accuracy': accuracy_report(y_orig, y_orig_logits),\n",
    "    '[Original] Log Loss': logloss_report(y_orig, y_orig_logits),\n",
    "    'Training time (sec)': training_time\n",
    "}\n",
    "\n",
    "report_df = pd.DataFrame(report, index=['']).T\n",
    "\n",
    "report_df.to_csv(f'reports/{NAME}.tsv', sep='\\t', header=False)\n",
    "\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}